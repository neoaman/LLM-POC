{"version":"NotebookV1","origId":3067557182516399,"name":"LLM 04b - Evaluating LLMs","language":"python","commands":[{"version":"CommandV1","origId":3067557182516416,"guid":"5085431a-d62b-45df-b764-eef372f0fd36","subtype":"command","commandType":"auto","position":18.0,"command":"%md\nYou may see some warning messages in the output above.  While pipelines are handy, they provide less control over the tokenizer and model; we will dive deeper later.\n\nBut first, let's see how our summarization pipeline does!  We'll compute 0/1 accuracy, a classic ML evaluation metric.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"29609052-1a12-4727-acb3-5f94363c1801"},{"version":"CommandV1","origId":3067557182516429,"guid":"5e687457-c8a1-4e9c-9034-6d49984d5f4d","subtype":"command","commandType":"auto","position":31.0,"command":"rouge_score.compute(\n    predictions=[\"Large language models beat world record\"],\n    references=[\"Large language models beating world records\"],\n    use_stemmer=True,\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"04710515-e42b-472f-911b-2df3dfe4a7b1"},{"version":"CommandV1","origId":3067557182516431,"guid":"f0a1977b-f56d-4c29-8621-fee8915be86e","subtype":"command","commandType":"auto","position":33.0,"command":"# What if we predict exactly 1 word correctly?\nrouge_score.compute(\n    predictions=[\"Large language models beat world record\"],\n    references=[\"Large\"],\n    use_stemmer=True,\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"614433d1-4858-4583-943a-df5516424d5e"},{"version":"CommandV1","origId":3067557182516448,"guid":"8c0ac680-4662-49cb-bc0d-5202046077fd","subtype":"command","commandType":"auto","position":50.0,"command":"def compare_models(models_results: dict) -> pd.DataFrame:\n    \"\"\"\n    :param models_results: dict of \"model name\" string mapped to pd.DataFrame of results computed by `compute_rouge_per_row`\n    :return: pd.DataFrame with 1 row per model, with columns: model, rouge1, rouge2, rougeL, rougeLsum\n    where metrics are averages over input results for each model\n    \"\"\"\n    agg_results = []\n    for r in models_results:\n        model_results = models_results[r].drop(\n            labels=[\"generated\", \"reference\"], axis=1\n        )\n        agg_metrics = [r]\n        agg_metrics[1:] = model_results.mean(axis=0)\n        agg_results.append(agg_metrics)\n    return pd.DataFrame(\n        agg_results, columns=[\"model\", \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n    )","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"e1d0b698-4685-4b48-87db-b59b113eb552"},{"version":"CommandV1","origId":3067557182516446,"guid":"b05357a7-ed12-4999-a2b2-e18d976633cd","subtype":"command","commandType":"auto","position":48.0,"command":"gpt2_results = compute_rouge_per_row(\n    generated_summaries=gpt2_summaries, reference_summaries=reference_summaries\n)\ndisplay(gpt2_results)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"0197245c-b3b9-4dd6-84e4-b1eb4997d6da"},{"version":"CommandV1","origId":3067557182516452,"guid":"70819914-7aed-4c43-9328-bb57f9f6ad21","subtype":"command","commandType":"auto","position":54.0,"command":"%md-sandbox\n&copy; 2023 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"0d03f656-3628-40bc-9ec2-903688c58ccf"},{"version":"CommandV1","origId":3067557182516401,"guid":"aecebe29-97cd-4cbb-a734-6f4b5a3970e8","subtype":"command","commandType":"auto","position":3.0,"command":"%md\n\n# Evaluating Large Language Models (LLMs)\nThis notebook demonstrates methods for evaluating LLMs.  We focus on the task of summarization and cover accuracy, ROUGE-N, and perplexity.\n\n### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n1. Know how to compute ROUGE-N and other metrics.\n2. Gain an intuitive understanding of ROUGE-N.\n3. Test various models and model sizes on the same data, and compare their results.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"eb9e8177-9666-44f2-9514-a1e681900656"},{"version":"CommandV1","origId":3067557182516440,"guid":"ce2daf65-f6ee-4e4d-9996-af0e26f4e093","subtype":"command","commandType":"auto","position":42.0,"command":"%md ### T5-base\n\nThe [T5-base](https://huggingface.co/t5-base) model has 220 million parameters.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"91ce59d0-e9af-4dc5-bd11-d22b8d654bf2"},{"version":"CommandV1","origId":3067557182516427,"guid":"90f52ce6-3526-48ab-a5c5-5afee67e76f2","subtype":"command","commandType":"auto","position":29.0,"command":"%md Stemming predictions and references can help to ignore minor differences.\n\nWe will use `rouge_score.compute()` directly for these hand-constructed examples.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"7c1b258a-e460-4aa3-b8d4-7e498623f8ac"},{"version":"CommandV1","origId":3067557182516433,"guid":"083e0996-4593-4795-a22e-3e5893129e30","subtype":"command","commandType":"auto","position":35.0,"command":"# What about 2 words?  Note how 'rouge1' and 'rouge2' compare with the case when we predict exactly 1 word correctly.\nrouge_score.compute(\n    predictions=[\"Large language\"],\n    references=[\"Large language models beat world record\"],\n    use_stemmer=True,\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"4472376e-b240-4015-9dcb-f27b78b71ed1"},{"version":"CommandV1","origId":3067557182516420,"guid":"14460910-5c34-418d-8895-44d18fb32f7d","subtype":"command","commandType":"auto","position":22.0,"command":"import evaluate\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download(\"punkt\")\n\nrouge_score = evaluate.load(\"rouge\")","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"ecb52587-7f21-45df-8bda-37c442b2f320"},{"version":"CommandV1","origId":3067557182516408,"guid":"32e13a8d-f8cb-4d38-b984-d2cf90a178b1","subtype":"command","commandType":"auto","position":10.0,"command":"display(sample.to_pandas())","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"5de8c559-3cc5-4a7a-a257-3825553640af"},{"version":"CommandV1","origId":3067557182516409,"guid":"c4d4b7c5-c00c-42bd-bb88-e7704807948a","subtype":"command","commandType":"auto","position":11.0,"command":"example_article = sample[\"article\"][0]\nexample_summary = sample[\"highlights\"][0]\nprint(f\"Article:\\n{example_article}\\n\")\nprint(f\"Summary:\\n{example_summary}\")","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"3b727c03-c845-4389-96af-9700058d0576"},{"version":"CommandV1","origId":3067557182516432,"guid":"02c0961f-772a-465b-8d43-7985f2b5a0c9","subtype":"command","commandType":"auto","position":34.0,"command":"# The ROUGE score is symmetric with respect to predictions and references.\nrouge_score.compute(\n    predictions=[\"Large\"],\n    references=[\"Large language models beat world record\"],\n    use_stemmer=True,\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"ad841cd8-6660-48d3-a451-59a0bdf85d9c"},{"version":"CommandV1","origId":3067557182516423,"guid":"c52811cf-28d2-4ca7-90f2-3befefe170af","subtype":"command","commandType":"auto","position":25.0,"command":"# ROUGE scores for our batch of articles\ncompute_rouge_score(t5_small_summaries, reference_summaries)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"c248f253-998b-4945-aeb8-4be450b6d6ed"},{"version":"CommandV1","origId":3067557182516404,"guid":"a1e6a62c-3337-4a24-9a74-2b3567ba26c3","subtype":"command","commandType":"auto","position":6.0,"command":"%run ../Includes/Classroom-Setup","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"6d2af9c4-0ae6-4368-bef9-55396f1ce548"},{"version":"CommandV1","origId":3067557182516451,"guid":"a3a399d8-76c9-4414-9d92-854ebe871956","subtype":"command","commandType":"auto","position":53.0,"command":"# In the output table below, scroll to the right to see all models.\ndisplay(\n    compare_models_summaries(\n        {\n            \"t5_small\": t5_small_results,\n            \"t5_base\": t5_base_results,\n            \"gpt2\": gpt2_results,\n        }\n    )\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"6fed957e-9c90-4b42-a098-2d3226ed7fec"},{"version":"CommandV1","origId":3067557182516428,"guid":"17578845-c5cf-492d-8d1c-68981eafc478","subtype":"command","commandType":"auto","position":30.0,"command":"rouge_score.compute(\n    predictions=[\"Large language models beat world record\"],\n    references=[\"Large language models beating world records\"],\n    use_stemmer=False,\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"59e15491-4e4d-4e62-95da-9c6fecfbbe74"},{"version":"CommandV1","origId":3067557182516419,"guid":"e219ad29-e13b-4843-9ed1-0fdd7e0c2404","subtype":"command","commandType":"auto","position":21.0,"command":"%md ## ROUGE\n\nNow that we can generate summaries---and we know 0/1 accuracy is useless here---let's look at how we can compute a meaningful metric designed to evaluate summarization: ROUGE.\n\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) is a set of evaluation metrics designed for comparing summaries from Lin et al., 2004.  See [Wikipedia](https://en.wikipedia.org/wiki/ROUGE_&#40;metric&#41;) for more info.  Here, we use the Hugging Face Evaluator wrapper to call into the `rouge_score` package.  This package provides 4 scores:\n\n* `rouge1`: ROUGE computed over unigrams (single words or tokens)\n* `rouge2`: ROUGE computed over bigrams (pairs of consecutive words or tokens)\n* `rougeL`: ROUGE based on the longest common subsequence shared by the summaries being compared\n* `rougeLsum`: like `rougeL`, but at \"summary level,\" i.e., ignoring sentence breaks (newlines)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"282de68d-1382-4b51-9041-aa40dda72716"},{"version":"CommandV1","origId":3067557182516400,"guid":"000fcc90-fecf-4f81-b790-7a1b852d8b98","subtype":"command","commandType":"auto","position":2.0,"command":"%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"1edda27c-c762-4df0-b75c-214764af64e9"},{"version":"CommandV1","origId":3067557182516424,"guid":"2fc08435-cc83-42e2-ac1a-a2dc0c971d27","subtype":"command","commandType":"auto","position":26.0,"command":"%md ## Understanding ROUGE scores","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"dc2c643b-8ffe-49a1-9fb4-1735325b8e35"},{"version":"CommandV1","origId":3067557182516405,"guid":"fad36437-b5bc-4d87-a1e3-a985fbb110ac","subtype":"command","commandType":"auto","position":7.0,"command":"%md ## How can we evaluate summarization?\n\nSuppose you are developing a smartphone news app and need to display automatically generated summaries of breaking news articles.  How can you evaluate whether or not the summaries you are generating are good?\n\n![](https://drive.google.com/uc?export=view&id=1V6cMD1LgivCb850JDhva1DO9EWVH8rJ7)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"acef7c63-0f35-4cf5-b133-f73fde31dfb9"},{"version":"CommandV1","origId":3067557182516436,"guid":"a7a8e02d-d525-422b-bb87-97286e85cad3","subtype":"command","commandType":"auto","position":38.0,"command":"def compute_rouge_per_row(\n    generated_summaries: list, reference_summaries: list\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe to compare rogue score metrics.\n    \"\"\"\n    generated_with_newlines = [\n        \"\\n\".join(sent_tokenize(s.strip())) for s in generated_summaries\n    ]\n    reference_with_newlines = [\n        \"\\n\".join(sent_tokenize(s.strip())) for s in reference_summaries\n    ]\n    scores = rouge_score.compute(\n        predictions=generated_with_newlines,\n        references=reference_with_newlines,\n        use_stemmer=True,\n        use_aggregator=False,\n    )\n    scores[\"generated\"] = generated_summaries\n    scores[\"reference\"] = reference_summaries\n    return pd.DataFrame.from_dict(scores)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"715aa9c9-2067-479d-ac6e-00d26246aa2c"},{"version":"CommandV1","origId":3067557182516414,"guid":"4d456972-65f6-45c8-9508-b16ebb48bfc6","subtype":"command","commandType":"auto","position":16.0,"command":"reference_summaries = sample[\"highlights\"]","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"ddafcc62-8941-4909-a649-5405f076b2d1"},{"version":"CommandV1","origId":3067557182516437,"guid":"1c3ef771-87d1-4275-b9ad-8f6747284cba","subtype":"command","commandType":"auto","position":39.0,"command":"%md ### T5-small\n\nThe [T5](https://huggingface.co/docs/transformers/model_doc/t5) [[paper]](https://arxiv.org/pdf/1910.10683.pdf) family of models are text-to-text transformers that have been trained on a multi-task mixture of unsupervised and supervised tasks. They are well suited for task such as summarization, translation, text classification, question answering, and more.\n\nThe t5-small version of the T5 models has 60 million parameters.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"c0d90858-e68c-436c-9fe0-e9a4385abb8d"},{"version":"CommandV1","origId":3067557182516439,"guid":"65dae7c9-e833-40ae-8eff-0958e7d78c23","subtype":"command","commandType":"auto","position":41.0,"command":"t5_small_results = compute_rouge_per_row(\n    generated_summaries=t5_small_summaries, reference_summaries=reference_summaries\n)\ndisplay(t5_small_results)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"b3719c36-86e9-4116-9893-85c381b0372c"},{"version":"CommandV1","origId":3067557182516407,"guid":"59647a40-db39-4d31-b7ea-4e96e23d7319","subtype":"command","commandType":"auto","position":9.0,"command":"import torch\nfrom datasets import load_dataset\n\nfull_dataset = load_dataset(\n    \"cnn_dailymail\", \"3.0.0\", cache_dir=DA.paths.datasets\n)  # Note: We specify cache_dir to use pre-cached data.\n\n# Use a small sample of the data during this lab, for speed.\nsample_size = 100\nsample = (\n    full_dataset[\"train\"]\n    .filter(lambda r: \"CNN\" in r[\"article\"][:25])\n    .shuffle(seed=42)\n    .select(range(sample_size))\n)\nsample","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"79915ea9-8851-4098-81af-2013645fe8be"},{"version":"CommandV1","origId":3067557182516450,"guid":"4554a187-9d13-469a-a7a6-7953b77f64f6","subtype":"command","commandType":"auto","position":52.0,"command":"def compare_models_summaries(models_summaries: dict) -> pd.DataFrame:\n    \"\"\"\n    Aggregates results from `models_summaries` and returns a dataframe.\n    \"\"\"\n    comparison_df = None\n    for model_name in models_summaries:\n        summaries_df = models_summaries[model_name]\n        if comparison_df is None:\n            comparison_df = summaries_df[[\"generated\"]].rename(\n                {\"generated\": model_name}, axis=1\n            )\n        else:\n            comparison_df = comparison_df.join(\n                summaries_df[[\"generated\"]].rename({\"generated\": model_name}, axis=1)\n            )\n    return comparison_df","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"48cee049-18bf-45e3-94de-e9b1f782b099"},{"version":"CommandV1","origId":3067557182516444,"guid":"d233bae3-ad48-43c9-90f8-3b9d15f6a34a","subtype":"command","commandType":"auto","position":46.0,"command":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n\ndef summarize_with_gpt2(\n    model_checkpoint: str, articles: list, batch_size: int = 8\n) -> list:\n    \"\"\"\n    Convenience function for summarization with GPT2 to handle these complications:\n    - Append \"TL;DR\" to the end of the input to get GPT2 to generate a summary.\n    https://huggingface.co/course/chapter7/5?fw=pt\n    - Truncate input to handle long articles.\n    - GPT2 uses a max token length of 1024.  We use a shorter 512 limit here.\n\n    :param model_checkpoint: reference to checkpointed model\n    :param articles: list of strings\n    :return: generated summaries, with the input and \"TL;DR\" removed\n    \"\"\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n    else:\n        device = \"cpu\"\n\n    tokenizer = GPT2Tokenizer.from_pretrained(\n        model_checkpoint, padding_side=\"left\", cache_dir=DA.paths.datasets\n    )\n    tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token})\n    model = GPT2LMHeadModel.from_pretrained(\n        model_checkpoint,\n        pad_token_id=tokenizer.eos_token_id,\n        cache_dir=DA.paths.datasets,\n    ).to(device)\n\n    def perform_inference(batch: list) -> list:\n        tmp_inputs = tokenizer(\n            batch, max_length=500, return_tensors=\"pt\", padding=True, truncation=True\n        )\n        tmp_inputs_decoded = tokenizer.batch_decode(\n            tmp_inputs.input_ids, skip_special_tokens=True\n        )\n        inputs = tokenizer(\n            [article + \" TL;DR:\" for article in tmp_inputs_decoded],\n            max_length=512,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n        )\n        summary_ids = model.generate(\n            inputs.input_ids.to(device),\n            attention_mask=inputs.attention_mask.to(device),\n            num_beams=2,\n            min_length=0,\n            max_length=512 + 32,\n        )\n        return tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n\n    decoded_summaries = []\n    for batch in batch_generator(articles, batch_size=batch_size):\n        decoded_summaries += perform_inference(batch)\n\n        # batch clean up\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    # post-process decoded summaries\n    summaries = [\n        summary[summary.find(\"TL;DR:\") + len(\"TL;DR: \") :]\n        for summary in decoded_summaries\n    ]\n\n    # cleanup\n    del tokenizer\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return summaries","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"952fe369-2b39-47c5-8d54-7b38cc2de83e"},{"version":"CommandV1","origId":3067557182516435,"guid":"ae09eb76-728d-41bf-a05a-55e1f18a5ba3","subtype":"command","commandType":"auto","position":37.0,"command":" %md ## Compare small and large models\n\n We've been working with the `t5-small` model so far.  Let's compare several models with different architectures in terms of their ROUGE scores and some example generated summaries.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"a1d1949f-21b7-4166-bdeb-ee7a84a32e91"},{"version":"CommandV1","origId":3067557182516403,"guid":"c4c2cc71-67a2-4164-9a20-48f1a4d26957","subtype":"command","commandType":"auto","position":5.0,"command":"%pip install rouge_score==0.1.2","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"309c9d83-fb0c-4268-8b4d-067cf17f5c34"},{"version":"CommandV1","origId":3067557182516418,"guid":"1e75d9f0-838a-4b6d-b5d8-19ee617ce324","subtype":"command","commandType":"auto","position":20.0,"command":"%md Accuracy zero?!?  We can see that the (very generic) metric of 0/1 accuracy is not useful for summarization.  Thinking about this more, small variations in wording may not matter much, and many different summaries may be equally valid.  So how can we evaluate summarization?","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"a6012b6e-2fc1-46cd-ab2b-1424af1c7168"},{"version":"CommandV1","origId":3067557182516425,"guid":"fdadc907-e336-441f-bdcc-2d206f581d9f","subtype":"command","commandType":"auto","position":27.0,"command":"# Sanity check: What if our predictions match the references exactly?\ncompute_rouge_score(reference_summaries, reference_summaries)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"991d899d-1f2b-4cc2-8736-a4b13a1d9cad"},{"version":"CommandV1","origId":3067557182516415,"guid":"52845235-8e56-4c73-be77-99e2c33faac8","subtype":"command","commandType":"auto","position":17.0,"command":"display(\n    pd.DataFrame.from_dict(\n        {\n            \"generated\": t5_small_summaries,\n            \"reference\": reference_summaries,\n        }\n    )\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"a9b38402-42a6-4949-870a-d057b7540359"},{"version":"CommandV1","origId":3067557182516410,"guid":"bca23e5d-f071-41ea-8b23-b8946b068051","subtype":"command","commandType":"auto","position":12.0,"command":"%md ## Summarization","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"3e1ea708-8f0b-4ca9-93bc-ddab005ad7c2"},{"version":"CommandV1","origId":3067557182516447,"guid":"ce4efd76-99c5-481f-ac2d-8f77bd4f2c2b","subtype":"command","commandType":"auto","position":49.0,"command":"%md ### Comparing all models\n\nWe use a couple of helper functions to compare the above models, first by their evaluation metrics (quantitative) and second by their generated summaries (qualitative).","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"53fd49d6-8e5e-4e0f-9b16-06c01ebb9bd2"},{"version":"CommandV1","origId":3067557182516422,"guid":"98a5aa4b-5083-471d-8ec2-91cbdfcb01c6","subtype":"command","commandType":"auto","position":24.0,"command":"def compute_rouge_score(generated: list, reference: list) -> dict:\n    \"\"\"\n    Compute ROUGE scores on a batch of articles.\n\n    This is a convenience function wrapping Hugging Face `rouge_score`,\n    which expects sentences to be separated by newlines.\n\n    :param generated: Summaries (list of strings) produced by the model\n    :param reference: Ground-truth summaries (list of strings) for comparison\n    \"\"\"\n    generated_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in generated]\n    reference_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in reference]\n    return rouge_score.compute(\n        predictions=generated_with_newlines,\n        references=reference_with_newlines,\n        use_stemmer=True,\n    )","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"a4f7be24-424f-44bb-b00a-97d796f45a4c"},{"version":"CommandV1","origId":3067557182516421,"guid":"98fbf3bc-c234-459a-ba3a-88a8697fc654","subtype":"command","commandType":"auto","position":23.0,"command":"%md You can call `rouge_score` evaluator directly, but we provide a convenience function below to handle the expected input format.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"e61c9ea4-834b-4a88-8b5d-649efab2a3ac"},{"version":"CommandV1","origId":3067557182516442,"guid":"db82b227-9a9c-4e64-9363-17f4786b11e8","subtype":"command","commandType":"auto","position":44.0,"command":"t5_base_results = compute_rouge_per_row(\n    generated_summaries=t5_base_summaries, reference_summaries=reference_summaries\n)\ndisplay(t5_base_results)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"31e2b728-a5c2-4229-b0c6-91d0950e0872"},{"version":"CommandV1","origId":3067557182516402,"guid":"1021bfb3-678f-465b-9594-dfafd5d87de2","subtype":"command","commandType":"auto","position":4.0,"command":"%md\n\n## Classroom Setup","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"0e2be4fa-aff8-4ec5-813e-766ac3d84eda"},{"version":"CommandV1","origId":3067557182516413,"guid":"0e421c2d-5a8e-4311-912d-306a638509ef","subtype":"command","commandType":"auto","position":15.0,"command":"t5_small_summaries = summarize_with_t5(\"t5-small\", sample[\"article\"])","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"9573ca42-29df-4bf4-a45f-e5934d2ee8c8"},{"version":"CommandV1","origId":3067557182516441,"guid":"60d5c5e0-b3b2-4d7f-ab69-3076fa7e9c7c","subtype":"command","commandType":"auto","position":43.0,"command":"t5_base_summaries = summarize_with_t5(\n    model_checkpoint=\"t5-base\", articles=sample[\"article\"]\n)\ncompute_rouge_score(t5_base_summaries, reference_summaries)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"3107442b-11bc-437f-b2be-fd09c02f683d"},{"version":"CommandV1","origId":3067557182516406,"guid":"a074559d-0fe4-435a-9b2d-f26a6fb9f911","subtype":"command","commandType":"auto","position":8.0,"command":"%md ## Dataset\n\nWe will use a subset of the `cnn_dailymail` dataset from See et al., 2017, downloadable from the [Hugging Face `datasets` hub](https://huggingface.co/datasets/cnn_dailymail).\n\nThis dataset provides news article paired with summaries (in the \"highlights\" column).  Let's load the data and take a look at some examples.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"9bf0f055-7576-496a-934e-b3714f17130b"},{"version":"CommandV1","origId":3067557182516430,"guid":"11474526-1c55-41a7-85b8-63b31987e05f","subtype":"command","commandType":"auto","position":32.0,"command":"%md Let's look at how the ROUGE score behaves in various situations.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"e9f858f7-339f-4537-aae8-03b0e16a62dd"},{"version":"CommandV1","origId":3067557182516434,"guid":"bf94aba0-680e-41c9-b1b2-a08130ed064a","subtype":"command","commandType":"auto","position":36.0,"command":"# Note how rouge1 differs from the rougeN (N>1) scores when we predict word subsequences correctly.\nrouge_score.compute(\n    predictions=[\"Models beat large language world record\"],\n    references=[\"Large language models beat world record\"],\n    use_stemmer=True,\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"ac95453f-e75b-4c91-a938-deecdc41668e"},{"version":"CommandV1","origId":3067557182516445,"guid":"8bfcf74f-2950-4e63-b29c-4d6dcc366837","subtype":"command","commandType":"auto","position":47.0,"command":"gpt2_summaries = summarize_with_gpt2(\n    model_checkpoint=\"gpt2\", articles=sample[\"article\"]\n)\ncompute_rouge_score(gpt2_summaries, reference_summaries)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"d7a8eb86-7af4-48e7-92fc-3694d5b8b10c"},{"version":"CommandV1","origId":3067557182516438,"guid":"706a027f-2ae9-47f9-a848-31ccb37ab70e","subtype":"command","commandType":"auto","position":40.0,"command":"# We computed t5_small_summaries above already.\ncompute_rouge_score(t5_small_summaries, reference_summaries)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"383df6e2-5873-4ac6-af76-034bbd529f7c"},{"version":"CommandV1","origId":3067557182516412,"guid":"a5ba36be-1c60-4bb8-8543-9e98a11df7bc","subtype":"command","commandType":"auto","position":14.0,"command":"def batch_generator(data: list, batch_size: int):\n    \"\"\"\n    Creates batches of size `batch_size` from a list.\n    \"\"\"\n    s = 0\n    e = s + batch_size\n    while s < len(data):\n        yield data[s:e]\n        s = e\n        e = min(s + batch_size, len(data))\n\n\ndef summarize_with_t5(\n    model_checkpoint: str, articles: list, batch_size: int = 8\n) -> list:\n    \"\"\"\n    Compute summaries using a T5 model.\n    This is similar to a `pipeline` for a T5 model but does tokenization manually.\n\n    :param model_checkpoint: Name for a model checkpoint in Hugging Face, such as \"t5-small\" or \"t5-base\"\n    :param articles: List of strings, where each string represents one article.\n    :return: List of strings, where each string represents one article's generated summary\n    \"\"\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n    else:\n        device = \"cpu\"\n\n    model = T5ForConditionalGeneration.from_pretrained(\n        model_checkpoint, cache_dir=DA.paths.datasets\n    ).to(device)\n    tokenizer = AutoTokenizer.from_pretrained(\n        model_checkpoint, model_max_length=1024, cache_dir=DA.paths.datasets\n    )\n\n    def perform_inference(batch: list) -> list:\n        inputs = tokenizer(\n            batch, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n        )\n\n        summary_ids = model.generate(\n            inputs.input_ids.to(device),\n            attention_mask=inputs.attention_mask.to(device),\n            num_beams=2,\n            min_length=0,\n            max_length=40,\n        )\n        return tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n\n    res = []\n\n    summary_articles = list(map(lambda article: \"summarize: \" + article, articles))\n    for batch in batch_generator(summary_articles, batch_size=batch_size):\n        res += perform_inference(batch)\n\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    # clean up\n    del tokenizer\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n    return res","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"4396d50f-0b55-45a7-8fd0-a51416994cd4"},{"version":"CommandV1","origId":3067557182516417,"guid":"7da55967-fbfa-41bb-80eb-db6fc11bf3db","subtype":"command","commandType":"auto","position":19.0,"command":"accuracy = 0.0\nfor i in range(len(reference_summaries)):\n    generated_summary = t5_small_summaries[i]\n    if generated_summary == reference_summaries[i]:\n        accuracy += 1.0\naccuracy = accuracy / len(reference_summaries)\n\nprint(f\"Achieved accuracy {accuracy}!\")","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"0c673e2e-6670-4cc6-b3bb-69acb443b8c7"},{"version":"CommandV1","origId":3067557182516449,"guid":"57d87a28-2ea3-43a2-9958-c40320998f68","subtype":"command","commandType":"auto","position":51.0,"command":"display(\n    compare_models(\n        {\n            \"t5-small\": t5_small_results,\n            \"t5-base\": t5_base_results,\n            \"gpt2\": gpt2_results,\n        }\n    )\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"064a11b2-a905-4990-9278-3312a716574c"},{"version":"CommandV1","origId":3067557182516443,"guid":"ada7903d-a87c-4313-86bc-5acb3d26353c","subtype":"command","commandType":"auto","position":45.0,"command":"%md ### GPT-2\n\nThe [GPT-2](https://huggingface.co/gpt2) model is a generative text model that was trained in a self-supervised fashion. Its strengths are in using a 'completing the sentence' for a given prompt.  It has 124 million parameters.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"63fe04cf-91ca-444f-8b19-b61741a1d6f2"},{"version":"CommandV1","origId":3067557182516411,"guid":"87127370-993d-43c6-b858-c82018ad415a","subtype":"command","commandType":"auto","position":13.0,"command":"import pandas as pd\nimport torch\nimport gc\nfrom transformers import AutoTokenizer, T5ForConditionalGeneration","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"0a638edb-a2e2-4bf6-ba4f-0f325e085c02"},{"version":"CommandV1","origId":3067557182516426,"guid":"e66eacfa-e4c4-466d-96f7-3d039a82134f","subtype":"command","commandType":"auto","position":28.0,"command":"# And what if we fail to predict anything?\ncompute_rouge_score(\n    generated=[\"\" for _ in range(len(reference_summaries))],\n    reference=reference_summaries,\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"5e4108dc-d3e9-4b0a-a2cb-3e6ec6d81bc3"}],"dashboards":[],"guid":"1aba42c1-fe79-4c69-9fd8-1644add7c479","globalVars":{},"iPythonMetadata":null,"inputWidgets":{},"notebookMetadata":{},"reposExportFormat":"SOURCE"}