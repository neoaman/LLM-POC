{"version":"NotebookV1","origId":3067557182516518,"name":"LLM 03L - Building LLM Chains Lab","language":"python","commands":[{"version":"CommandV1","origId":3067557182516549,"guid":"bb310dd0-f380-4741-b3fa-c5216d10845e","subtype":"command","commandType":"auto","position":32.0,"command":"%md \n### Question 4\n","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"c03f043f-67c8-46fb-9140-53ff742428ce"},{"version":"CommandV1","origId":3067557182516543,"guid":"258eb34b-228e-4c85-a60b-378c7e49cb9e","subtype":"command","commandType":"auto","position":26.0,"command":"%md \n### Question 2\n\nLet's see if we can do what we did with the laptop reviews. \n\nThink about what is likely to happen now. Will this command succeed? \n\n(***Hint: think about the maximum sequence length of a model***)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"848879e2-6c99-4f16-951f-6fbb8c022f9e"},{"version":"CommandV1","origId":3067557182516524,"guid":"c4ee40f6-28d8-4d95-8956-c4963a87fb1d","subtype":"command","commandType":"auto","position":7.0,"command":"%run ../Includes/Classroom-Setup","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"c11ff83c-d7ea-418b-9306-1d40c9c9e3c0"},{"version":"CommandV1","origId":3067557182516520,"guid":"e1f25f3a-c5cb-48d1-9180-97d956a1d5c6","subtype":"command","commandType":"auto","position":3.0,"command":"%md\n\n# Lab: Adding Our Own Data to a Multi-Stage Reasoning System\n\n### Working with external knowledge bases \nIn this notebook we're going to augment the knowledge base of our LLM with additional data. We will split the notebook into two halves:\n- First, we will walk through how to load in a relatively small, local text file using a `DocumentLoader`, split it into chunks, and store it in a vector database using `ChromaDB`.\n- Second, you will get a chance to show what you've learned by building a larger system with the complete works of Shakespeare. \n----\n### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n\nBy the end of this notebook, you will be able to:\n1. Add external local data to your LLM's knowledge base via a vector database.\n2. Construct a Question-Answer(QA) LLMChain to \"talk to your data.\"\n3. Load external data sources from remote locations and store in a vector database.\n4. Leverage different retrieval methods to search over your data. ","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"633203d4-9d5e-405c-b5c9-5750d9b97077"},{"version":"CommandV1","origId":3067557182516525,"guid":"f259f0ae-58a3-4ece-9df1-32a033465146","subtype":"command","commandType":"auto","position":8.0,"command":"%md Fill in your credentials.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"b656db11-4f27-48d0-a13e-c7c3f403c67d"},{"version":"CommandV1","origId":3067557182516548,"guid":"9d7e22ea-c0dc-4cef-836d-8eca65a35b31","subtype":"command","commandType":"auto","position":31.0,"command":"# Test your answer. DO NOT MODIFY THIS CELL.\n\ndbTestQuestion3_3(qa, query_results_venice)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"3c384b7b-b3f7-4030-84bc-0aaa4ad84091"},{"version":"CommandV1","origId":3067557182516529,"guid":"fbdc25cc-a2eb-439f-a269-5d60d5e561af","subtype":"command","commandType":"auto","position":12.0,"command":"from langchain.vectorstores import Chroma\nfrom langchain.document_loaders import TextLoader\n\n# We have some fake laptop reviews that we can load in\nlaptop_reviews = TextLoader(\n    f\"{DA.paths.datasets}/reviews/fake_laptop_reviews.txt\", encoding=\"utf8\"\n)\ndocument = laptop_reviews.load()\ndisplay(document)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"50df5c19-3ff5-42fe-b1c2-6da1470032de"},{"version":"CommandV1","origId":3067557182516544,"guid":"3d5a1aa6-04af-4cd8-a12a-6efedb0ba5f9","subtype":"command","commandType":"auto","position":27.0,"command":"# TODO\n# Let's start with the simplest method: \"Stuff\" which puts all of the data into the prompt and asks a question of it:\nqa = RetrievalQA.from_chain_type(<FILL_IN>)\nquery = \"What happens in the play Hamlet?\"\n# Run the query\nquery_results_hamlet = <FILL_IN>\n\nquery_results_hamlet","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"924e7308-6d27-4ac4-90b8-bb5feda6bc58"},{"version":"CommandV1","origId":3067557182516533,"guid":"ac8ffc7a-6c00-46e0-bc43-694f3e012ec1","subtype":"command","commandType":"auto","position":16.0,"command":"from langchain.chains import RetrievalQA\nfrom langchain.llms import HuggingFacePipeline\n\n# We want to make this a retriever, so we need to convert our index.  This will create a wrapper around the functionality of our vector database so we can search for similar documents/chunks in the vectorstore and retrieve the results:\nretriever = chromadb_index.as_retriever()\n\n# This chain will be used to do QA on the document. We will need\n# 1 - A LLM to do the language interpretation\n# 2 - A vector database that can perform document retrieval\n# 3 - Specification on how to deal with this data (more on this soon)\n\nhf_llm = HuggingFacePipeline.from_model_id(\n    model_id=\"google/flan-t5-large\",\n    task=\"text2text-generation\",\n    model_kwargs={\n        \"temperature\": 0,\n        \"max_length\": 128,\n        \"cache_dir\": DA.paths.datasets,\n    },\n)\n\nchain_type = \"stuff\"  # Options: stuff, map_reduce, refine, map_rerank\nlaptop_qa = RetrievalQA.from_chain_type(\n    llm=hf_llm, chain_type=\"stuff\", retriever=retriever\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"2374db63-2688-4179-9e78-96a6a6672be1"},{"version":"CommandV1","origId":3067557182516542,"guid":"8ccbe064-548a-4368-9e3f-f5a2ef7c19da","subtype":"command","commandType":"auto","position":25.0,"command":"# Test your answer. DO NOT MODIFY THIS CELL.\n\ndbTestQuestion3_1(embeddings, chromadb_index)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"57ed951a-23e0-4a49-8d31-3ee47aa8b745"},{"version":"CommandV1","origId":3067557182516552,"guid":"bc0b7394-c255-417e-b59b-09c24f158e9f","subtype":"command","commandType":"auto","position":35.0,"command":"%md ## Submit your Results (edX Verified Only)\n\nTo get credit for this lab, click the submit button in the top right to report the results. If you run into any issues, click `Run` -> `Clear state and run all`, and make sure all tests have passed before re-submitting. If you accidentally deleted any tests, take a look at the notebook's version history to recover them or reload the notebooks.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"bffd94eb-dea5-49ca-9281-35eabf44e36d"},{"version":"CommandV1","origId":3067557182516527,"guid":"f4cf80d2-55fc-44cc-b18b-a584b0fd8d26","subtype":"command","commandType":"auto","position":10.0,"command":"%md \n## Building a Personalized Document Oracle\n\nIn this notebook, we're going to build a special type of LLMChain that will enable us to ask questions of our data. We will be able to \"speak to our data\".","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"bfe00020-170d-4aa7-ac65-f19fcf91b870"},{"version":"CommandV1","origId":3067557182516541,"guid":"efb9863e-801b-489d-94e6-f79baaddbf00","subtype":"command","commandType":"auto","position":24.0,"command":"# TODO\ntext_splitter = <FILL_IN> #hint try chunk sizes of 1024 and an overlap of 256 (this will take approx. 10mins with this model to build our vector database index)\ntexts = <FILL_IN>\n\nmodel_name = <FILL_IN> #hint, try \"sentence-transformers/all-MiniLM-L6-v2\" as your model\nembeddings = <FILL_IN>\nchromadb_index = <FILL_IN>","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"b7b6fee7-309d-4412-891c-6be1ced47288"},{"version":"CommandV1","origId":3067557182516523,"guid":"fcf96654-9eea-4ad5-8e0d-9311f66f4609","subtype":"command","commandType":"auto","position":6.0,"command":"dbutils.library.restartPython()","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"1b6a6a07-5ef8-47ff-908e-681eeb6bc016"},{"version":"CommandV1","origId":3067557182516530,"guid":"62419926-1dc0-4607-baca-a69f3af110d5","subtype":"command","commandType":"auto","position":13.0,"command":"%md \n### Step 2 - Chunking and Embeddings\n\nNow that we have the data in document format, we will split data into chunks using a `CharacterTextSplitter` and embed this data using Hugging Face's embedding LLM to embed this data for our vector store.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"c7856a7f-4795-466f-b337-9d35460e158a"},{"version":"CommandV1","origId":3067557182516536,"guid":"bf82039f-ed15-41f8-88ad-8128d54551ba","subtype":"command","commandType":"auto","position":19.0,"command":"# Now we'll ask the chain about the product.\nlaptop_features = laptop_qa.run(\"What are some of the laptop's features?\")\ndisplay(laptop_features)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"33367d7d-3519-40f5-84ef-506f00c524dc"},{"version":"CommandV1","origId":3067557182516545,"guid":"77f194e4-c759-43d8-996f-a59b1429228c","subtype":"command","commandType":"auto","position":28.0,"command":"# Test your answer. DO NOT MODIFY THIS CELL.\n\ndbTestQuestion3_2(qa, query_results_hamlet)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"e4527b5d-5d03-407b-a751-829a46791ee7"},{"version":"CommandV1","origId":3067557182516534,"guid":"b128cbed-c064-4056-9782-3a74de3bd180","subtype":"command","commandType":"auto","position":17.0,"command":"%md \n### Step 4 - Talking to Our Data\nNow we are ready to send prompts to our LLM and have it use our prompt, the access to our data, and read the information, process, and return with a response.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"65c8ccd6-ac3e-4b81-9583-7a979458b475"},{"version":"CommandV1","origId":3067557182516531,"guid":"5044e1d3-378a-4252-a835-00bfefd6091e","subtype":"command","commandType":"auto","position":14.0,"command":"from langchain.text_splitter import CharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nimport tempfile\n\ntmp_laptop_dir = tempfile.TemporaryDirectory()\ntmp_shakespeare_dir = tempfile.TemporaryDirectory()\n\n# First we split the data into manageable chunks to store as vectors. There isn't an exact way to do this, more chunks means more detailed context, but will increase the size of our vectorstore.\ntext_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=10)\ntexts = text_splitter.split_documents(document)\n# Now we'll create embeddings for our document so we can store it in a vector store and feed the data into an LLM. We'll use the sentence-transformers model for out embeddings. https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models/\nmodel_name = \"sentence-transformers/all-MiniLM-L6-v2\"\nembeddings = HuggingFaceEmbeddings(\n    model_name=model_name, cache_folder=DA.paths.datasets\n)  # Use a pre-cached model\n# Finally we make our Index using chromadb and the embeddings LLM\nchromadb_index = Chroma.from_documents(\n    texts, embeddings, persist_directory=tmp_laptop_dir.name\n)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"49a500cb-996d-4674-bfbf-52423ed7d6aa"},{"version":"CommandV1","origId":3067557182516537,"guid":"15575dd5-3002-45f3-8186-df6ffc4931e1","subtype":"command","commandType":"auto","position":20.0,"command":"# Finally let's ask the chain about the reviews.\nlaptop_reviews = laptop_qa.run(\"What is the general sentiment of the reviews?\")\ndisplay(laptop_reviews)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"b844e3cf-854c-44b1-a01f-0cfe0bf3d8f5"},{"version":"CommandV1","origId":3067557182516526,"guid":"49d6b68c-269e-4dd2-a0a5-ba118c071c39","subtype":"command","commandType":"auto","position":9.0,"command":"# TODO\n# For many of the services that we'll using in the notebook, we'll need a HuggingFace API key so this cell will ask for it:\n# HuggingFace Hub: https://huggingface.co/inference-api\n\nimport os\nos.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"<FILL IN>\"","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"26f1a9fb-5acf-4cf7-907d-37fee9a93248"},{"version":"CommandV1","origId":3067557182516539,"guid":"ef7c8274-07cd-4e51-80ce-334439c0c212","subtype":"command","commandType":"auto","position":22.0,"command":"from langchain.document_loaders import GutenbergLoader\n\nloader = GutenbergLoader(\n    \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n)  # Complete works of Shakespeare in a txt file\n\nall_shakespeare_text = loader.load()","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"bad8b055-a92a-4b7b-b5e9-7c61e4a9125f"},{"version":"CommandV1","origId":3067557182516546,"guid":"654bab27-cbd4-444d-9d9d-c834e039a87f","subtype":"command","commandType":"auto","position":29.0,"command":"%md \n### Question 3\n\nNow that we're working with larger documents, we should be mindful of the input sequence limitations that our LLM has. \n\nChain Types for document loader:\n\n- [`stuff`](https://docs.langchain.com/docs/components/chains/index_related_chains#stuffing) - Stuffing is the simplest method, whereby you simply stuff all the related data into the prompt as context to pass to the language model.\n- [`map_reduce`](https://docs.langchain.com/docs/components/chains/index_related_chains#map-reduce) - This method involves running an initial prompt on each chunk of data (for summarization tasks, this could be a summary of that chunk; for question-answering tasks, it could be an answer based solely on that chunk).\n- [`refine`](https://docs.langchain.com/docs/components/chains/index_related_chains#refine) - This method involves running an initial prompt on the first chunk of data, generating some output. For the remaining documents, that output is passed in, along with the next document, asking the LLM to refine the output based on the new document.\n- [`map_rerank`](https://docs.langchain.com/docs/components/chains/index_related_chains#map-rerank) - This method involves running an initial prompt on each chunk of data, that not only tries to complete a task but also gives a score for how certain it is in its answer. The responses are then ranked according to this score, and the highest score is returned.\n  * NOTE: For this exercise, `map_rerank` will [error](https://github.com/hwchase17/langchain/issues/3970).","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"d5c2911f-8e59-48a7-91ca-1f31db3b353b"},{"version":"CommandV1","origId":3067557182516535,"guid":"beb9014c-a253-496c-9d5f-a765e4e87b3b","subtype":"command","commandType":"auto","position":18.0,"command":"# Let's ask the chain about the product we have.\nlaptop_name = laptop_qa.run(\"What is the full name of the laptop?\")\ndisplay(laptop_name)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"cbc4338d-d268-4861-84e3-078472557ce5"},{"version":"CommandV1","origId":3067557182516550,"guid":"f5b49ab4-f890-4c1f-acdd-571a72c6b278","subtype":"command","commandType":"auto","position":33.0,"command":"# TODO\n# That's much better! Let's try another type\n\nqa = RetrievalQA.from_chain_type(llm=hf_llm, chain_type=<FILL_IN>, retriever=chromadb_index.as_retriever())\nquery = \"What happens to romeo and juliet?\"\nquery_results_romeo = <FILL_IN>\n\nquery_results_romeo","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"eca98861-e92c-4e89-aaf5-13581cbf1adf"},{"version":"CommandV1","origId":3067557182516528,"guid":"89533f6f-1146-4ffc-a7fc-771471de39b1","subtype":"command","commandType":"auto","position":11.0,"command":"%md \n### Step 1 - Loading Documents into our Vector Store\nFor this system we'll leverage the [ChromaDB vector database](https://www.trychroma.com/) and load in some text we have on file. This file is of a hypothetical laptop being reviewed in both long form and with brief customer reviews. We'll use LangChain's `TextLoader` to load this data.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"fa2eb04a-384a-44d8-b215-29b1392148d7"},{"version":"CommandV1","origId":3067557182516521,"guid":"340c86bd-4bb2-46b4-8c4a-0c2d2e1872dc","subtype":"command","commandType":"auto","position":4.0,"command":"%md\n\n## Classroom Setup","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"48fac8cc-d879-4fa1-9be7-0767a5c72939"},{"version":"CommandV1","origId":3067557182516553,"guid":"ab58b39a-a91c-40b8-8b3a-1adbc7b34663","subtype":"command","commandType":"auto","position":36.0,"command":"tmp_laptop_dir.cleanup()\ntmp_shakespeare_dir.cleanup()","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"8d6ef45d-b4b9-4f72-bc3c-34b3907b5841"},{"version":"CommandV1","origId":3067557182516522,"guid":"26077700-6cab-4fdd-9d53-4056b274f5c5","subtype":"command","commandType":"auto","position":5.0,"command":"%pip install chromadb==0.4.10 tiktoken==0.3.3 sqlalchemy==2.0.15 langchain==0.0.249","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"4efed7ac-6278-4b01-843d-10a9e90ddd8f"},{"version":"CommandV1","origId":3067557182516554,"guid":"a7756441-efea-4da1-996b-58fb5374b52c","subtype":"command","commandType":"auto","position":37.0,"command":"%md-sandbox\n&copy; 2023 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"bbca07f8-a85e-49e1-b89b-a83183b7d41e"},{"version":"CommandV1","origId":3067557182516540,"guid":"177a8079-9129-4af1-9862-fbd10be45fc4","subtype":"command","commandType":"auto","position":23.0,"command":"%md\n### Question 1\n\nNow it's your turn! Based on what we did previously, fill in the missing parts below to build your own QA LLMChain.","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"3b6e784e-f6b5-4cb0-9c83-6d8cc22fdb52"},{"version":"CommandV1","origId":3067557182516551,"guid":"bd08d6ae-6f2f-476e-ad6a-ea8b8e796785","subtype":"command","commandType":"auto","position":34.0,"command":"# Test your answer. DO NOT MODIFY THIS CELL.\n\ndbTestQuestion3_4(qa, query_results_romeo)","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"288cfe92-c8b6-4a8c-9e61-b1a1114d8750"},{"version":"CommandV1","origId":3067557182516538,"guid":"5e65b401-16f8-4af9-908d-fa5005f9fe77","subtype":"command","commandType":"auto","position":21.0,"command":"%md \n## Exercise: Working with larger documents\nThis document was relatively small. So let's see if we can work with something bigger. To show how well we can scale the vector database, let's load in a larger document. For this we'll get data from the [Gutenberg Project](https://www.gutenberg.org/) where thousands of free-to-access texts. We'll use the complete works of William Shakespeare.\n\nInstead of a local text document, we'll download the complete works of Shakespeare using the `GutenbergLoader` that works with the Gutenberg project: https://www.gutenberg.org","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"d1e790b4-7cfd-483f-a189-be6b9d267c5b"},{"version":"CommandV1","origId":3067557182516532,"guid":"f757caaf-762a-4cd2-ac1f-ca3d17a6c1b8","subtype":"command","commandType":"auto","position":15.0,"command":"%md \n### Step 3 - Creating our Document QA LLM Chain\nWith our data now in vector form we need an LLM and a chain to take our queries and create tasks for our LLM to perform. ","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"7b761fd8-705a-4fc6-9a3d-8a8871fdc647"},{"version":"CommandV1","origId":3067557182516519,"guid":"a55fea4c-f41c-41fa-aabf-006a4e229ce0","subtype":"command","commandType":"auto","position":2.0,"command":"%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"8354018e-2f57-4487-b392-d355bb151608"},{"version":"CommandV1","origId":3067557182516547,"guid":"ff6c050c-41fd-45bd-a72e-b14f991d558e","subtype":"command","commandType":"auto","position":30.0,"command":"# TODO\nqa = RetrievalQA.from_chain_type(llm=hf_llm, chain_type=<FILL_IN>, retriever=chromadb_index.as_retriever())\nquery = \"Who is the main character in the Merchant of Venice?\"\nquery_results_venice = <FILL_IN>\n\nquery_results_venice","commandVersion":1,"state":"finished","results":null,"resultDbfsStatus":"INLINED_IN_TREE","resultDbfsErrorMessage":null,"errorSummary":null,"errorTraceType":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"metadata":{},"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"tableResultIndex":null,"listResultMetadata":[],"subcommandOptions":null,"contentSha256Hex":null,"nuid":"98c3264c-12e0-4b3a-b1fa-7bf11a0c96f7"}],"dashboards":[],"guid":"2a269b90-1bf6-4ee4-81b9-7786a5dbfefe","globalVars":{},"iPythonMetadata":null,"inputWidgets":{},"notebookMetadata":{},"reposExportFormat":"SOURCE"}