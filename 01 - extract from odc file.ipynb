{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileLocation = 'large-language-models.dbc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Contents from the .dbc file (usually one file or a directory) ***\n",
      "\n",
      "['manifest.mf', 'Large-Language-Models-v2.0.0']\n"
     ]
    }
   ],
   "source": [
    "# Cleanup from prior run\n",
    "import shutil\n",
    "try: shutil.rmtree('tmp_dbc')\n",
    "except OSError: pass\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "try: os.mkdir('tmp_dbc')\n",
    "except OSError: pass\n",
    "with zipfile.ZipFile(fileLocation, 'r') as z:\n",
    "    z.extractall('tmp_dbc')\n",
    "\n",
    "print ('*** Contents from the .dbc file (usually one file or a directory) ***\\n')\n",
    "print (os.listdir('tmp_dbc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Files to be created (relative to your current working directory) ***\n",
      "(Warning: files will be overwritten!)\n",
      "\n",
      "./Version Info_export.ipynb\n",
      "LLM 05 - Society and LLMs/LLM 05L - LLMs and Society Lab_export.ipynb\n",
      "LLM 05 - Society and LLMs/LLM 05 - LLMs and Society_export.ipynb\n",
      "LLM 03 - Multi-stage Reasoning/LLM 03 - Building LLM Chains_export.ipynb\n",
      "LLM 03 - Multi-stage Reasoning/LLM 03L - Building LLM Chains Lab_export.ipynb\n",
      "Includes/Reset_export.ipynb\n",
      "Includes/Classroom-Setup_export.ipynb\n",
      "Includes/Test-Framework_export.ipynb\n",
      "Includes/Workspace-Setup_export.ipynb\n",
      "Includes/_common_export.ipynb\n",
      "Includes/Print-Dataset-Copyrights_export.ipynb\n",
      "LLM 04 - Fine-tuning and Evaluating LLMs/LLM 04b - Evaluating LLMs_export.ipynb\n",
      "LLM 04 - Fine-tuning and Evaluating LLMs/LLM 04L - Fine-tuning LLMs Lab_export.ipynb\n",
      "LLM 04 - Fine-tuning and Evaluating LLMs/LLM 04a - Fine-tuning LLMs_export.ipynb\n",
      "LLM 01 - Applications with LLMs/LLM 01 - LLMs with Hugging Face_export.ipynb\n",
      "LLM 01 - Applications with LLMs/LLM 01L - LLMs with Hugging Face Lab_export.ipynb\n",
      "LLM 02 - Embeddings, Vector Databases, and Search/LLM 02b - Weaviate [OPTIONAL]_export.ipynb\n",
      "LLM 02 - Embeddings, Vector Databases, and Search/LLM 02a - Pinecone [OPTIONAL]_export.ipynb\n",
      "LLM 02 - Embeddings, Vector Databases, and Search/LLM 02 - Embeddings, Vector Databases, and Search_export.ipynb\n",
      "LLM 02 - Embeddings, Vector Databases, and Search/LLM 02L - Embeddings, Vector Databases, and Search_export.ipynb\n",
      "LLM 00 - Introduction/LLM 00a - Install Datasets_export.ipynb\n",
      "LLM 00 - Introduction/LLM 00b - Introduction to Databricks_export.ipynb\n",
      "LLM 06 - LLMOps/LLM 06 - LLMOps_export.ipynb\n"
     ]
    }
   ],
   "source": [
    "import fnmatch\n",
    "\n",
    "filesToParse = []\n",
    "for root, dirNames, fileNames in os.walk('tmp_dbc'):\n",
    "    for fileName in fnmatch.filter(fileNames, '*.python'):\n",
    "        filesToParse.append((root, fileName))\n",
    "\n",
    "def getIpynbName(path, fileName):\n",
    "    path = os.path.normpath(path)\n",
    "    pathSplit = path.split(os.sep)[2:]\n",
    "    baseDir = os.path.join(*pathSplit) if len(pathSplit) > 0 else '.'\n",
    "    newFileName = os.path.splitext(fileName)[0] + '_export.ipynb'\n",
    "    return os.path.join(baseDir, newFileName)\n",
    "\n",
    "print (\"*** Files to be created (relative to your current working directory) ***\")\n",
    "print (\"(Warning: files will be overwritten!)\\n\")\n",
    "for path, fileName in filesToParse:\n",
    "    print (getIpynbName(path, fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: ./Version Info_export.ipynb\n",
      "Created: LLM 05 - Society and LLMs/LLM 05L - LLMs and Society Lab_export.ipynb\n",
      "Created: LLM 05 - Society and LLMs/LLM 05 - LLMs and Society_export.ipynb\n",
      "Created: LLM 03 - Multi-stage Reasoning/LLM 03 - Building LLM Chains_export.ipynb\n",
      "Created: LLM 03 - Multi-stage Reasoning/LLM 03L - Building LLM Chains Lab_export.ipynb\n",
      "Created: Includes/Reset_export.ipynb\n",
      "Created: Includes/Classroom-Setup_export.ipynb\n",
      "Created: Includes/Test-Framework_export.ipynb\n",
      "Created: Includes/Workspace-Setup_export.ipynb\n",
      "Created: Includes/_common_export.ipynb\n",
      "Created: Includes/Print-Dataset-Copyrights_export.ipynb\n",
      "Created: LLM 04 - Fine-tuning and Evaluating LLMs/LLM 04b - Evaluating LLMs_export.ipynb\n",
      "Created: LLM 04 - Fine-tuning and Evaluating LLMs/LLM 04L - Fine-tuning LLMs Lab_export.ipynb\n",
      "Created: LLM 04 - Fine-tuning and Evaluating LLMs/LLM 04a - Fine-tuning LLMs_export.ipynb\n",
      "Created: LLM 01 - Applications with LLMs/LLM 01 - LLMs with Hugging Face_export.ipynb\n",
      "Created: LLM 01 - Applications with LLMs/LLM 01L - LLMs with Hugging Face Lab_export.ipynb\n",
      "Created: LLM 02 - Embeddings, Vector Databases, and Search/LLM 02b - Weaviate [OPTIONAL]_export.ipynb\n",
      "Created: LLM 02 - Embeddings, Vector Databases, and Search/LLM 02a - Pinecone [OPTIONAL]_export.ipynb\n",
      "Created: LLM 02 - Embeddings, Vector Databases, and Search/LLM 02 - Embeddings, Vector Databases, and Search_export.ipynb\n",
      "Created: LLM 02 - Embeddings, Vector Databases, and Search/LLM 02L - Embeddings, Vector Databases, and Search_export.ipynb\n",
      "Created: LLM 00 - Introduction/LLM 00a - Install Datasets_export.ipynb\n",
      "Created: LLM 00 - Introduction/LLM 00b - Introduction to Databricks_export.ipynb\n",
      "Created: LLM 06 - LLMOps/LLM 06 - LLMOps_export.ipynb\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import nbformat\n",
    "from nbformat.v3.nbpy import PyReader\n",
    "import json\n",
    "import re\n",
    "\n",
    "_header = u'# -*- coding: utf-8 -*-\\n# <nbformat>3.0</nbformat>\\n'\n",
    "_markdownCell = u'\\n\\n# <markdowncell>\\n\\n'\n",
    "_codeCell = u'\\n\\n# <codecell>\\n\\n'\n",
    "_firstCell = u\"\"\"# Increase compatibility with Databricks\n",
    "from IPython.display import display as idisplay, HTML\n",
    "displayHTML = lambda x: idisplay(HTML(x))\n",
    "def display(*args, **kargs): pass\"\"\"\n",
    "\n",
    "def convertToIpynb(fileToParse):\n",
    "    \n",
    "    with codecs.open(os.path.join(*fileToParse), encoding=\"utf-8\") as fp:\n",
    "        jsonData = json.load(fp)\n",
    "        commands = jsonData['commands']\n",
    "        commandInfo = [(x['position'], x['command']) for x in commands]\n",
    "        commandList = sorted(commandInfo)\n",
    "\n",
    "    with codecs.open('tmp_ipynb.py', 'w', encoding=\"utf-8\") as fp:\n",
    "        fp.write(_header)\n",
    "        fp.write(_codeCell)\n",
    "        fp.write(_firstCell)\n",
    "\n",
    "        for position, command in commandList:\n",
    "            if re.match(r'\\s*%md', command):\n",
    "                command = re.sub(r'^\\s*%md', '', command, flags=re.MULTILINE)\n",
    "                command = re.sub(r'(%\\(|\\)%)', '$', command)\n",
    "                command = re.sub(r'(%\\[|\\]%)', '$$', command)\n",
    "\n",
    "                fp.write(_markdownCell)\n",
    "                asLines = command.split('\\n')\n",
    "                command = '# ' + '\\n# '.join(asLines)\n",
    "            else:\n",
    "                command = re.sub(r'^\\s*baseDir\\s*=.*$', 'baseDir = \\'data\\'', \n",
    "                                 command, flags=re.MULTILINE)\n",
    "                fp.write(_codeCell)\n",
    "\n",
    "            fp.write(command)\n",
    "\n",
    "    outputName = getIpynbName(*fileToParse)\n",
    "\n",
    "    with codecs.open('tmp_ipynb.py', 'r', encoding=\"utf-8\") as intermediate:\n",
    "        nb = PyReader().read(intermediate)\n",
    "\n",
    "    os.remove('tmp_ipynb.py')\n",
    "    baseDirectory = os.path.split(outputName)[0]\n",
    "\n",
    "    if not os.path.isdir(baseDirectory):\n",
    "        os.makedirs(baseDirectory)\n",
    "\n",
    "    with codecs.open(outputName, 'w', encoding=\"utf-8\") as output:\n",
    "        nbformat.write(nbformat.convert(nb, 4.0), output)  \n",
    "        print ('Created: {0}'.format(outputName))\n",
    "\n",
    "for fileToParse in filesToParse:\n",
    "    convertToIpynb(fileToParse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
